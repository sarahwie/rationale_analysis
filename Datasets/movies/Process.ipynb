{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-10 16:07:35--  http://www.eraserbenchmark.com/zipped/movies.tar.gz\n",
      "Resolving www.eraserbenchmark.com (www.eraserbenchmark.com)... 52.5.68.140, 54.158.230.58, 35.168.162.120, ...\n",
      "Connecting to www.eraserbenchmark.com (www.eraserbenchmark.com)|52.5.68.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3899487 (3.7M) [application/gzip]\n",
      "Saving to: ‘movies.tar.gz.1’\n",
      "\n",
      "movies.tar.gz.1     100%[===================>]   3.72M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-04-10 16:07:36 (37.8 MB/s) - ‘movies.tar.gz.1’ saved [3899487/3899487]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.eraserbenchmark.com/zipped/movies.tar.gz\n",
    "!tar -xzf movies.tar.gz\n",
    "!mv movies/val.jsonl movies/dev.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rationale_benchmark.utils import load_flattened_documents\n",
    "documents = load_flattened_documents('movies', docids=None)\n",
    "def read_annotations(json_file) :\n",
    "    anns = [json.loads(line) for line in open(json_file)]\n",
    "    for a in anns :\n",
    "        doc_id = a['annotation_id']\n",
    "        a['document'] = \" \".join(documents[doc_id])\n",
    "        a['label'] = a['classification']\n",
    "        del a['classification']\n",
    "        a['rationale'] = []\n",
    "        for evgroup in a['evidences'] :\n",
    "            for ev in evgroup :\n",
    "                assert ev['docid'] == doc_id\n",
    "                a['rationale'].append((ev['start_token'], ev['end_token']))\n",
    "        del a['evidences']\n",
    "        del a['query_type']\n",
    "        del a['query']\n",
    "        \n",
    "    return anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('data/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['train', 'dev', 'test'] :\n",
    "    ann = read_annotations('movies/' + key + '.jsonl')\n",
    "    with open('data/' + key + '.jsonl', 'w') as f :\n",
    "        f.write('\\n'.join([json.dumps(line) for line in ann]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
